{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKPM6BBy4CsX"
   },
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2930,
     "status": "ok",
     "timestamp": 1749654334839,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "fdeBxJUxxHTc",
    "outputId": "3870e49b-cff3-4ef6-97a5-4dcfa43f1f81",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.023321Z",
     "start_time": "2025-07-23T15:38:00.016602Z"
    }
   },
   "source": [
    "# Packages should be pre-installed in the environment\n",
    "# Dependencies: langgraph langchain-openai langchain-core langchain-google-genai pyyaml\n",
    "pass"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMSXkOax4EwC"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749654334849,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "J1MmjJpO357j",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.065075Z",
     "start_time": "2025-07-23T15:38:00.057582Z"
    }
   },
   "source": [
    "from typing import TypedDict, Dict, List, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1749654334892,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "89oCQIAI5BUf",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.124111Z",
     "start_time": "2025-07-23T15:38:00.117844Z"
    }
   },
   "source": [
    "import os\n",
    "import yaml\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import re\n",
    "import tempfile\n",
    "from typing import Dict"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6SG7LXHhMX8"
   },
   "source": [
    "# API key"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1749654334933,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "fFE7aN5BxUiC",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.177306Z",
     "start_time": "2025-07-23T15:38:00.163030Z"
    }
   },
   "source": [
    "# # Read API key from environment variable or file\n",
    "# from dotenv import load_dotenv\n",
    "# # First try to get API key from environment variable (for Cloud Run)\n",
    "# load_dotenv()\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "# print(api_key)\n",
    "api_key_source = \"environment variable\"\n",
    "\n",
    "if api_key:\n",
    "    print(f\"‚úÖ API key loaded from environment variable\")\n",
    "else:\n",
    "    # Fallback to file-based approach for local development\n",
    "    # Get current working directory and script directory\n",
    "    current_dir = os.getcwd()\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else current_dir\n",
    "\n",
    "    # Try to find the api_key file in multiple possible locations\n",
    "    possible_paths = [\n",
    "        'api_key',  # Current directory\n",
    "        os.path.join(script_dir, 'api_key'),  # Same directory as script/notebook\n",
    "        os.path.join(current_dir, '..', 'api_key'),  # Parent directory (flask-app level)\n",
    "        os.path.join(script_dir, '..', 'api_key'),  # Parent of script directory\n",
    "        '/Users/leo/Documents/uni/master/25sose/NLP-social/WEBDEMO/flask-app/api_key',  # Flask app directory\n",
    "        '/Users/leo/Documents/uni/master/25sose/NLP-social/WEBDEMO/flask-app/backend/api_key'  # Backend directory\n",
    "    ]\n",
    "\n",
    "    api_key_source = None\n",
    "\n",
    "    for path in possible_paths:\n",
    "        try:\n",
    "            if os.path.exists(path):\n",
    "                with open(path, 'r') as f:\n",
    "                    api_key = f.read().strip()\n",
    "                api_key_source = path\n",
    "                print(f\"‚úÖ API key loaded from file: {path}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if api_key is None:\n",
    "        print(\"‚ùå API key not found in environment variable or any file location.\")\n",
    "        print(f\"   Current working directory: {current_dir}\")\n",
    "        print(\"   For Cloud Run: Set GOOGLE_API_KEY environment variable\")\n",
    "        print(\"   For local development: Create an 'api_key' file with your Google API key\")\n",
    "        print(\"   Searched file paths:\")\n",
    "        for path in possible_paths:\n",
    "            abs_path = os.path.abspath(path)\n",
    "            exists = \"‚úì\" if os.path.exists(path) else \"‚úó\"\n",
    "            print(f\"   {exists} {path} -> {abs_path}\")\n",
    "        print(\"   Get your API key from: https://aistudio.google.com/app/apikey\")\n",
    "\n",
    "# Uncomment and use these if you prefer environment variables instead:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key loaded from environment variable\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgiyYknF4IjC"
   },
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oet6ZqhWZuYo"
   },
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1749654334935,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "zem3UumH2OWa",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.306255Z",
     "start_time": "2025-07-23T15:38:00.302098Z"
    }
   },
   "source": [
    "# # Initialize LLM\n",
    "# llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF5MKsCqYEw4"
   },
   "source": [
    "## Gemini\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/rate-limits"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749654334936,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "E4NNrDwQ3_no",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.358282Z",
     "start_time": "2025-07-23T15:38:00.352217Z"
    }
   },
   "source": [
    "# # Initialize Gemini LLM (using free model)\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-2.5-flash-preview-05-20\",  # Free model\n",
    "#     temperature=0.7,\n",
    "#     google_api_key=api_key\n",
    "# )"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1749654334937,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "KqgORfyLYGV6",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:00.412215Z",
     "start_time": "2025-07-23T15:38:00.394230Z"
    }
   },
   "source": [
    "# Initialize Gemini LLM (using free model)\n",
    "if api_key:\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash-001\",  # Free model\n",
    "        temperature=0.3,\n",
    "        google_api_key=api_key\n",
    "    )\n",
    "    print(\"‚úÖ LLM gemini-2.0-flash-001 initialized successfully\")\n",
    "else:\n",
    "    llm = None\n",
    "    print(\"‚ùå Cannot initialize LLM - no API key available\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM gemini-2.0-flash-001 initialized successfully\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test API connection"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:01.867916Z",
     "start_time": "2025-07-23T15:38:00.608116Z"
    }
   },
   "source": [
    "# Test API connection\n",
    "if llm is not None:\n",
    "    try:\n",
    "        print(\"üîç Testing API connection...\")\n",
    "        test_response = llm.invoke([{\"role\": \"user\", \"content\": \"Hello, can you respond with just 'API connection successful'?\"}])\n",
    "        print(f\"‚úÖ API test successful: {test_response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API connection failed: {e}\")\n",
    "        print(\"\\nPossible solutions:\")\n",
    "        print(\"1. Check your internet connection\")\n",
    "        print(\"2. Verify your API key is correct and active\")\n",
    "        print(\"3. Check if you have sufficient API quota\")\n",
    "        print(\"4. Try again in a few moments (rate limiting)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot test API - LLM not initialized\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing API connection...\n",
      "‚úÖ API test successful: API connection successful\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Connection Issues\n",
    "\n",
    "If you're experiencing connection errors, try these solutions:\n",
    "\n",
    "### Common Issues:\n",
    "1. **Invalid API Key**: Make sure your API key is correct and active\n",
    "2. **Network Issues**: Check your internet connection\n",
    "3. **Rate Limiting**: Google API has rate limits - wait a few minutes and try again\n",
    "4. **Quota Exceeded**: Check your API usage quota at [Google AI Studio](https://aistudio.google.com/)\n",
    "5. **Firewall/Proxy**: Corporate networks might block API calls\n",
    "\n",
    "### Quick Fixes:\n",
    "- Restart the notebook kernel and try again\n",
    "- Verify the `api_key` file contains only your API key (no extra spaces/characters)\n",
    "- Try running the API test cell above to isolate the issue\n",
    "- Check [Google AI Studio](https://aistudio.google.com/app/apikey) to verify your key is working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZago6r8Ao01"
   },
   "source": [
    "# Cases"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749654334939,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "jAvQ2RXYAru8",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:01.916698Z",
     "start_time": "2025-07-23T15:38:01.908718Z"
    }
   },
   "source": [
    "def load_case_from_file(file_path: str, scenario_number: int = None) -> str:\n",
    "    \"\"\"Load case details from text file\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the case file\n",
    "        scenario_number: If file contains multiple scenarios, specify which one (1, 2, 3, etc.)\n",
    "\n",
    "    Returns:\n",
    "        Case details as string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read().strip()\n",
    "\n",
    "        # Check if file contains multiple scenarios\n",
    "        if 'Scenario 1:' in content and 'Scenario 2:' in content:\n",
    "            scenarios = {}\n",
    "\n",
    "            # Split by scenario markers\n",
    "            parts = content.split('Scenario ')\n",
    "            for part in parts[1:]:  # Skip first empty part\n",
    "                if ':' in part:\n",
    "                    scenario_num = int(part.split(':')[0].strip())\n",
    "                    scenario_text = 'Scenario ' + part\n",
    "                    scenarios[scenario_num] = scenario_text.strip()\n",
    "\n",
    "            if scenario_number:\n",
    "                if scenario_number in scenarios:\n",
    "                    return scenarios[scenario_number]\n",
    "                else:\n",
    "                    available = list(scenarios.keys())\n",
    "                    raise ValueError(f\"Scenario {scenario_number} not found. Available scenarios: {available}\")\n",
    "            else:\n",
    "                # Return all scenarios combined\n",
    "                return content\n",
    "        else:\n",
    "            # Single case file\n",
    "            return content\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Case file {file_path} not found\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading case from {file_path}: {e}\")"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1749654334942,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "bh1yPaVQAx_L",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:01.961134Z",
     "start_time": "2025-07-23T15:38:01.948003Z"
    }
   },
   "source": [
    "def select_scenario(scenarios: Dict[str, str]) -> str:\n",
    "    \"\"\"Allow user to select a scenario from loaded cases\"\"\"\n",
    "    if not scenarios:\n",
    "        return None\n",
    "\n",
    "    print(\"\\nAvailable scenarios:\")\n",
    "    scenario_list = list(scenarios.keys())\n",
    "\n",
    "    for i, scenario in enumerate(scenario_list, 1):\n",
    "        # Extract just the scenario title for display\n",
    "        title = scenario\n",
    "        if ':' in scenarios[scenario]:\n",
    "            first_line = scenarios[scenario].split('\\n')[0]\n",
    "            if 'Background:' in first_line:\n",
    "                title = f\"{scenario} - Murder case with eyewitness evidence\"\n",
    "        print(f\"{i}. {title}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"\\nSelect scenario (1-{len(scenario_list)}) or 'back': \")\n",
    "            if choice.lower() == 'back':\n",
    "                return None\n",
    "\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(scenario_list):\n",
    "                selected_scenario = scenario_list[choice_num - 1]\n",
    "                case_details = scenarios[selected_scenario]\n",
    "\n",
    "                # Display selected case\n",
    "                print(f\"\\n=== SELECTED CASE ===\")\n",
    "                print(case_details[:500] + \"...\" if len(case_details) > 500 else case_details)\n",
    "                print(\"=\" * 50)\n",
    "\n",
    "                confirm = input(\"\\nUse this scenario? (y/n): \")\n",
    "                if confirm.lower() in ['y', 'yes']:\n",
    "                    return case_details\n",
    "            else:\n",
    "                print(f\"Please enter a number between 1 and {len(scenario_list)}\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654334946,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "Xufn0Gpkmgk6",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.005624Z",
     "start_time": "2025-07-23T15:38:01.995851Z"
    }
   },
   "source": [
    "def initialize_with_case(case_file_path: str, scenario_number: int = None):\n",
    "    \"\"\"Initialize the system with a case from file\"\"\"\n",
    "    global current_case, current_case_filename, current_scenario_number\n",
    "\n",
    "    try:\n",
    "        current_case = load_case_from_file(case_file_path, scenario_number)\n",
    "        current_case_filename = case_file_path  # Track the filename\n",
    "        current_scenario_number = scenario_number  # Track the scenario number\n",
    "\n",
    "        if scenario_number:\n",
    "            print(f\"‚úÖ Loaded Scenario {scenario_number} from {case_file_path}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Loaded case from {case_file_path}\")\n",
    "\n",
    "        # Show preview of the case\n",
    "        preview = current_case[:200] + \"...\" if len(current_case) > 200 else current_case\n",
    "        print(f\"Case Preview: {preview}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading case: {e}\")\n",
    "        raise"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1749654334994,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "Gy8xGI8DFqge",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.058108Z",
     "start_time": "2025-07-23T15:38:02.050080Z"
    }
   },
   "source": [
    "def list_scenarios_in_file(file_path: str):\n",
    "    \"\"\"List available scenarios in a case file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        scenarios = []\n",
    "        parts = content.split('Scenario ')\n",
    "        for part in parts[1:]:\n",
    "            if ':' in part:\n",
    "                scenario_num = int(part.split(':')[0].strip())\n",
    "                # Get first line after the colon as title\n",
    "                title_line = part.split('\\n')[0] if '\\n' in part else part[:50]\n",
    "                scenarios.append((scenario_num, title_line))\n",
    "\n",
    "        return scenarios\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return []\n"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRABptMi4Kjv"
   },
   "source": [
    "# Jury"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1749654334997,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "-JAcLg5c2JNw",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.112408Z",
     "start_time": "2025-07-23T15:38:02.105612Z"
    }
   },
   "source": [
    "class JuryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    case_details: str\n",
    "    jury_backgrounds: Dict[str, str]\n",
    "    current_round: int\n",
    "    current_juror_index: int  # Track which juror is speaking within the round\n",
    "    total_rounds: int  # Total number of deliberation rounds\n",
    "    jury_order: List[str]  # Order of jury members"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1749654334998,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "t2Ote-E82paj",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.164210Z",
     "start_time": "2025-07-23T15:38:02.156999Z"
    }
   },
   "source": [
    "# Jury members and their backgrounds - FALLBACK\n",
    "JURY_MEMBERS = {\n",
    "    \"Alice\": \"Retired teacher, 30 years experience. Values fairness and second chances.\",\n",
    "    \"Bob\": \"Small business owner. Practical, fact-focused, believes in personal responsibility.\",\n",
    "    \"Carol\": \"Social worker with family court experience. Empathetic, considers circumstances.\",\n",
    "    \"David\": \"Engineer with technical background. Data-driven, prefers clear evidence.\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oo7X33-5Jm1"
   },
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1749654335000,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "S3PC_aAy2sjW",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.210081Z",
     "start_time": "2025-07-23T15:38:02.201278Z"
    }
   },
   "source": [
    "def load_backgrounds_from_files(file_paths: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Load jury backgrounds from text files (legacy function for backward compatibility)\"\"\"\n",
    "    backgrounds = {}\n",
    "    jury_names = list(JURY_MEMBERS.keys())\n",
    "\n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        if i >= len(jury_names):\n",
    "            break\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                backgrounds[jury_names[i]] = f.read().strip()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {file_path} not found, using default background\")\n",
    "            backgrounds[jury_names[i]] = JURY_MEMBERS[jury_names[i]]\n",
    "\n",
    "    # Fill remaining with defaults\n",
    "    for name in jury_names[len(file_paths):]:\n",
    "        backgrounds[name] = JURY_MEMBERS[name]\n",
    "\n",
    "    return backgrounds"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LftDGc0h5LAi"
   },
   "source": [
    "## YAML"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1749654335001,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "KPfbioq8k-Bp",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.274582Z",
     "start_time": "2025-07-23T15:38:02.251117Z"
    }
   },
   "source": [
    "def load_backgrounds_from_yaml(file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load jury backgrounds from YAML file supporting multiple structures\"\"\"\n",
    "    backgrounds = {}\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "\n",
    "        for jury_key, jury_data in data.items():\n",
    "            # Detect structure type by checking for key fields\n",
    "            if 'first_name' in jury_data and 'last_name' in jury_data:\n",
    "                # Detailed structure (like jurors.yaml)\n",
    "                background = _process_detailed_structure(jury_data)\n",
    "                full_name = f\"{jury_data.get('first_name', 'Unknown')} {jury_data.get('last_name', 'Unknown')}\"\n",
    "\n",
    "            elif 'backstory' in jury_data:\n",
    "                # Simplified structure (like agents.yaml, old_and_young.yaml)\n",
    "                background = _process_simplified_structure(jury_data)\n",
    "                full_name = _extract_name_from_backstory(jury_data.get('backstory', ''), jury_key)\n",
    "\n",
    "            else:\n",
    "                # Unknown structure - use available data\n",
    "                background = _process_unknown_structure(jury_data)\n",
    "                full_name = jury_key.replace('_', ' ').title()\n",
    "\n",
    "            backgrounds[full_name] = background\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"YAML file {file_path} not found, using default backgrounds\")\n",
    "        return JURY_MEMBERS.copy() if 'JURY_MEMBERS' in globals() else {}\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"Error parsing YAML file {file_path}: {e}\")\n",
    "        return JURY_MEMBERS.copy() if 'JURY_MEMBERS' in globals() else {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading backgrounds from {file_path}: {e}\")\n",
    "        return JURY_MEMBERS.copy() if 'JURY_MEMBERS' in globals() else {}\n",
    "\n",
    "    return backgrounds\n",
    "\n",
    "\n",
    "def _process_detailed_structure(jury_data: Dict) -> str:\n",
    "    \"\"\"Process detailed structure with separate fields for personal information\"\"\"\n",
    "    biography = jury_data.get('biography', '')\n",
    "    age = jury_data.get('age', 'Unknown age')\n",
    "    education = jury_data.get('education', 'Unknown education')\n",
    "    occupation = jury_data.get('occupation', 'Unknown occupation')\n",
    "    income = jury_data.get('income', 'Unknown income')\n",
    "    state = jury_data.get('state', 'Unknown state')\n",
    "    religion = jury_data.get('religion', 'Unknown religion')\n",
    "    race = jury_data.get('race', 'Unknown race')\n",
    "    gender = jury_data.get('gender', 'Unknown gender')\n",
    "    goal = jury_data.get('goal', 'Serve justice fairly')\n",
    "    role = jury_data.get('role', 'Regular juror')\n",
    "\n",
    "    # Combine all information into a comprehensive background\n",
    "    background = f\"{biography}\\n\\n\"\n",
    "    background += f\"Personal Details: {age}, {gender}, {race}, {education}, {occupation} from {state}. \"\n",
    "    background += f\"Income: {income}. Religion: {religion}.\\n\"\n",
    "    background += f\"Role: {role}\\n\"\n",
    "    background += f\"Goal: {goal}\"\n",
    "\n",
    "    return background\n",
    "\n",
    "\n",
    "def _process_simplified_structure(jury_data: Dict) -> str:\n",
    "    \"\"\"Process simplified structure with backstory, role, and goal\"\"\"\n",
    "    backstory = jury_data.get('backstory', '').strip()\n",
    "    role = jury_data.get('role', '').strip()\n",
    "    goal = jury_data.get('goal', '').strip()\n",
    "\n",
    "    # Clean up multiline strings and remove template placeholders\n",
    "    backstory = re.sub(r'\\s+', ' ', backstory)\n",
    "    role = re.sub(r'\\s+', ' ', role)\n",
    "    goal = re.sub(r'\\s+', ' ', goal)\n",
    "\n",
    "    # Remove template placeholders like {topic} and {current_year}\n",
    "    backstory = re.sub(r'\\{[^}]+\\}', '[case topic]', backstory)\n",
    "    role = re.sub(r'\\{[^}]+\\}', '[case topic]', role)\n",
    "    goal = re.sub(r'\\{[^}]+\\}', '[case topic]', goal)\n",
    "\n",
    "    background = f\"{backstory}\\n\\n\"\n",
    "    if role and role != backstory:\n",
    "        background += f\"Role: {role}\\n\"\n",
    "    if goal and goal != backstory:\n",
    "        background += f\"Goal: {goal}\"\n",
    "\n",
    "    return background.strip()\n",
    "\n",
    "\n",
    "def _process_unknown_structure(jury_data: Dict) -> str:\n",
    "    \"\"\"Process unknown structure by using all available string data\"\"\"\n",
    "    background_parts = []\n",
    "\n",
    "    for key, value in jury_data.items():\n",
    "        if isinstance(value, str) and value.strip():\n",
    "            # Clean up multiline strings\n",
    "            clean_value = re.sub(r'\\s+', ' ', value.strip())\n",
    "            background_parts.append(f\"{key.replace('_', ' ').title()}: {clean_value}\")\n",
    "\n",
    "    return \"\\n\".join(background_parts) if background_parts else \"No background information available.\"\n",
    "\n",
    "\n",
    "def _extract_name_from_backstory(backstory: str, fallback_key: str) -> str:\n",
    "    \"\"\"Extract a name from the backstory text, with fallback to jury key\"\"\"\n",
    "    if not backstory:\n",
    "        return fallback_key.replace('_', ' ').title()\n",
    "\n",
    "    # Look for name patterns in the backstory\n",
    "    # Pattern 1: \"Name is a...\" or \"Name, a...\"\n",
    "    name_pattern1 = r'^([A-Z][a-z]+ [A-Z][a-z]+)\\s+(?:is|,)'\n",
    "    match1 = re.search(name_pattern1, backstory)\n",
    "    if match1:\n",
    "        return match1.group(1)\n",
    "\n",
    "    # Pattern 2: Just first sentence that might contain a name\n",
    "    name_pattern2 = r'^([A-Z][a-z]+ [A-Z][a-z]+)'\n",
    "    match2 = re.search(name_pattern2, backstory)\n",
    "    if match2:\n",
    "        return match2.group(1)\n",
    "\n",
    "    # Pattern 3: Look for any capitalized name in the first 50 characters\n",
    "    name_pattern3 = r'([A-Z][a-z]+ [A-Z][a-z]+)'\n",
    "    match3 = re.search(name_pattern3, backstory[:50])\n",
    "    if match3:\n",
    "        return match3.group(1)\n",
    "\n",
    "    # Fallback to jury key\n",
    "    return fallback_key.replace('_', ' ').title()\n"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749654335023,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "R_6Fne1unUMx",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.324640Z",
     "start_time": "2025-07-23T15:38:02.315404Z"
    }
   },
   "source": [
    "def initialize_with_yaml(yaml_file_path: str, total_rounds: int = 3):\n",
    "    \"\"\"Initialize the graph with jury data from YAML file\"\"\"\n",
    "    global graph, jury_backgrounds, current_total_rounds, current_jury_filename\n",
    "\n",
    "    if llm is None:\n",
    "        print(\"Cannot initialize - API key not configured\")\n",
    "        return\n",
    "\n",
    "    graph, jury_backgrounds, current_total_rounds = create_jury_graph(yaml_file=yaml_file_path, total_rounds=total_rounds)\n",
    "    current_total_rounds = total_rounds\n",
    "    current_jury_filename = yaml_file_path  # Track the filename\n",
    "\n",
    "    print(f\"Loaded jury members from {yaml_file_path}:\")\n",
    "    for name in jury_backgrounds.keys():\n",
    "        print(f\"  - {name}\")\n",
    "    print(f\"Set to {total_rounds} deliberation rounds\")\n",
    "    print()\n"
   ],
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0jjONU4k_C4"
   },
   "source": [
    "## Create jury node"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Rate Limiting Configuration\n",
    "\n",
    "Google Gemini API has these free tier limits:\n",
    "- **15 requests per minute** for gemini-2.0-flash\n",
    "- **1,500 requests per day** for free tier\n",
    "\n",
    "The notebook includes automatic rate limiting and retry logic to handle quota exceeded errors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1749654335031,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "-tv-mNf0SQHK",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.399251Z",
     "start_time": "2025-07-23T15:38:02.381900Z"
    }
   },
   "source": [
    "def create_jury_node(jury_name: str):\n",
    "    \"\"\"Create a jury member node function\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    def jury_response(state: JuryState):\n",
    "        if llm is None:\n",
    "            message = AIMessage(content=\"Cannot generate response - API key not configured\", name=jury_name)\n",
    "            return {\"messages\": [message]}\n",
    "\n",
    "        background = state[\"jury_backgrounds\"][jury_name]\n",
    "        case = state[\"case_details\"]\n",
    "        current_round = state.get(\"current_round\", 1)\n",
    "        current_juror_index = state.get(\"current_juror_index\", 0)\n",
    "\n",
    "        # # Get recent conversation\n",
    "        # recent_msgs = state[\"messages\"][-6:] if len(state[\"messages\"]) > 6 else state[\"messages\"]\n",
    "\n",
    "        # # Get messages from the last two rounds\n",
    "        # recent_msgs = get_last_two_rounds_context(state[\"messages\"], current_round)\n",
    "\n",
    "        # context = \"\\n\".join([f\"{getattr(msg, 'name', 'User')}: {msg.content}\" for msg in recent_msgs])\n",
    "\n",
    "        # Get FULL conversation history\n",
    "        all_messages = state[\"messages\"]\n",
    "        deliberation_msgs = []\n",
    "        for msg in all_messages:\n",
    "            # Skip the initial case presentation (HumanMessage)\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                continue\n",
    "            # For AIMessages, check if they have a name attribute\n",
    "            if isinstance(msg, AIMessage) and hasattr(msg, 'name'):\n",
    "                # Skip \"=== X ===\" style moderator messages but include other moderator messages\n",
    "                if msg.name == \"Moderator\" and \"===\" in msg.content:\n",
    "                    continue\n",
    "                # Include all other messages (juror deliberations and non-procedural moderator messages)\n",
    "                deliberation_msgs.append(f\"{msg.name}: {msg.content}\")\n",
    "        context = \"\\n\".join(deliberation_msgs)\n",
    "\n",
    "        prompt = f\"\"\"You are {jury_name}, a jury member in Round {current_round} of deliberation.\n",
    "Background: {background}\n",
    "\n",
    "Case: {case}\n",
    "\n",
    "Full deliberation so far:\n",
    "{context}\n",
    "\n",
    "As {jury_name}, give your perspective on this case. Consider what others have said and build on the discussion. Keep it to 2-3 sentences and be conversational.\n",
    "\n",
    "At the end of your response, indicate your current stance by adding:\n",
    "[Current stance: GUILTY/NOT GUILTY] - [brief reason referencing the deliberation]\"\"\"\n",
    "\n",
    "        # Add rate limiting and retry logic\n",
    "        max_retries = 3\n",
    "        base_delay = 5  # seconds\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Add a small delay between requests to avoid rate limiting\n",
    "                if attempt > 0:\n",
    "                    delay = base_delay * (2 ** attempt) + random.uniform(0, 2)\n",
    "                    print(f\"‚è≥ Rate limit hit for {jury_name}, waiting {delay:.1f} seconds...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    # Small delay even on first attempt\n",
    "                    time.sleep(random.uniform(1, 3))\n",
    "                \n",
    "                response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                message = AIMessage(content=response.content, name=jury_name)\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                if \"429\" in error_msg or \"quota\" in error_msg.lower():\n",
    "                    if attempt < max_retries - 1:\n",
    "                        continue  # Retry with longer delay\n",
    "                    else:\n",
    "                        print(f\"‚ùå Rate limit exceeded for {jury_name} after {max_retries} attempts\")\n",
    "                        message = AIMessage(content=f\"I need more time to consider this case due to system limitations.\", name=jury_name)\n",
    "                else:\n",
    "                    print(f\"Error generating response for {jury_name}: {e}\")\n",
    "                    message = AIMessage(content=f\"I need more time to consider this case.\", name=jury_name)\n",
    "                break\n",
    "\n",
    "        # Advance to next juror\n",
    "        next_juror_index = current_juror_index + 1\n",
    "\n",
    "        return {\n",
    "            \"messages\": [message],\n",
    "            \"current_juror_index\": next_juror_index\n",
    "        }\n",
    "\n",
    "    return jury_response\n"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.468264Z",
     "start_time": "2025-07-23T15:38:02.458591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_last_two_rounds_context(messages: List[BaseMessage], current_round: int) -> List[BaseMessage]:\n",
    "    \"\"\"Extract messages from the last two rounds of deliberation\"\"\"\n",
    "\n",
    "    # Early return for initial rounds\n",
    "    if current_round <= 2 or len(messages) <= 6:  # Fallback to at least 6 messages\n",
    "        return messages\n",
    "\n",
    "    # Track round transitions\n",
    "    round_transitions = {}\n",
    "\n",
    "    for i, msg in enumerate(messages):\n",
    "        if hasattr(msg, 'name') and msg.name == \"Moderator\":\n",
    "            if \"=== DELIBERATION ROUND\" in msg.content:\n",
    "                try:\n",
    "                    # Extract round number\n",
    "                    round_str = msg.content.split(\"ROUND \")[1].split(\" ===\")[0]\n",
    "                    round_num = int(round_str)\n",
    "                    round_transitions[round_num] = i\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "\n",
    "    # Determine starting index\n",
    "    if current_round == 1:\n",
    "        # Include all messages\n",
    "        start_idx = 0\n",
    "    elif current_round == 2:\n",
    "        # Include from round 1 onwards\n",
    "        start_idx = round_transitions.get(1, 0)\n",
    "    else:\n",
    "        # Include from two rounds ago\n",
    "        two_rounds_ago = current_round - 1\n",
    "        start_idx = round_transitions.get(two_rounds_ago, 0)\n",
    "\n",
    "        # Fallback: if we can't find the round marker, use last N messages\n",
    "        if start_idx == 0 and len(messages) > 12:\n",
    "            # Estimate ~4-6 messages per round, so ~12 for 2 rounds\n",
    "            start_idx = len(messages) - 12\n",
    "\n",
    "    return messages[start_idx:]"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqieUwB1AY0_"
   },
   "source": [
    "# Moderator"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335036,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "Vm3myTIbRtq6",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.531271Z",
     "start_time": "2025-07-23T15:38:02.523475Z"
    }
   },
   "source": [
    "def moderator(state: JuryState):\n",
    "    \"\"\"Enhanced moderator to manage multi-round deliberations\"\"\"\n",
    "    current_round = state.get(\"current_round\", 0)\n",
    "    current_juror_index = state.get(\"current_juror_index\", 0)\n",
    "    total_rounds = state.get(\"total_rounds\", 3)\n",
    "\n",
    "    # Only announce the very beginning of deliberation\n",
    "    if current_round == 0 and current_juror_index == 0:\n",
    "        msg = AIMessage(content=\"=== JURY DELIBERATION BEGINS ===\", name=\"Moderator\")\n",
    "        return {\n",
    "            \"messages\": [msg],\n",
    "            \"current_round\": current_round,\n",
    "            \"current_juror_index\": current_juror_index\n",
    "        }\n",
    "\n",
    "    # For all other cases, just pass through without messages\n",
    "    return {\n",
    "        \"current_round\": current_round,\n",
    "        \"current_juror_index\": current_juror_index\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7PUl8IBAdA1"
   },
   "source": [
    "# Final Verdict"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1749654335060,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "if2myPnBBGhc",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.600215Z",
     "start_time": "2025-07-23T15:38:02.583815Z"
    }
   },
   "source": [
    "def final_verdict(state: JuryState):\n",
    "    \"\"\"Collect final verdicts from all jury members\"\"\"\n",
    "    import time\n",
    "    import random\n",
    "    \n",
    "    if llm is None:\n",
    "        summary = \"=== FINAL VERDICTS ===\\nCannot collect verdicts - API key not configured\"\n",
    "        return {\"messages\": [AIMessage(content=summary, name=\"Final_Verdict\")]}\n",
    "\n",
    "    case = state[\"case_details\"]\n",
    "\n",
    "    # # Get summary of key discussion points\n",
    "    # discussion_summary = get_deliberation_summary(state[\"messages\"])\n",
    "\n",
    "    # Get FULL conversation history\n",
    "    all_messages = state[\"messages\"]\n",
    "    deliberation_msgs = []\n",
    "    for msg in all_messages:\n",
    "        # Skip the initial case presentation (HumanMessage)\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            continue\n",
    "        # For AIMessages, check if they have a name attribute\n",
    "        if isinstance(msg, AIMessage) and hasattr(msg, 'name'):\n",
    "            # Skip \"=== X ===\" style moderator messages but include other moderator messages\n",
    "            if msg.name == \"Moderator\" and \"===\" in msg.content:\n",
    "                continue\n",
    "            # Include all other messages (juror deliberations and non-procedural moderator messages)\n",
    "            deliberation_msgs.append(f\"{msg.name}: {msg.content}\")\n",
    "    context = \"\\n\".join(deliberation_msgs)\n",
    "    # print(context)\n",
    "\n",
    "    # Get all jury members' final decisions\n",
    "    verdicts = {}\n",
    "    for i, jury_name in enumerate(state[\"jury_backgrounds\"].keys()):\n",
    "        background = state[\"jury_backgrounds\"][jury_name]\n",
    "\n",
    "        prompt = f\"\"\"You are {jury_name}, a jury member.\n",
    "Background: {background}\n",
    "\n",
    "Case: {case}\n",
    "\n",
    "Full deliberation transcript:\n",
    "{context}\n",
    "\n",
    "After the full deliberation, what is your FINAL VERDICT?\n",
    "Consider the arguments made during the discussion and explain how they influenced your decision.\n",
    "Answer only: \"GUILTY\" or \"NOT GUILTY\" and give one sentence explaining why.\n",
    "\n",
    "Format: VERDICT: [GUILTY/NOT GUILTY] - [brief reason referencing the deliberation]\"\"\"\n",
    "\n",
    "        # Add rate limiting between verdict requests\n",
    "        max_retries = 3\n",
    "        base_delay = 4\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Progressive delay to avoid rate limits\n",
    "                if attempt > 0:\n",
    "                    delay = base_delay * (2 ** attempt) + random.uniform(0, 2)\n",
    "                    print(f\"‚è≥ Rate limit hit collecting verdict from {jury_name}, waiting {delay:.1f} seconds...\")\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    # Delay between jurors to avoid rapid requests\n",
    "                    if i > 0:  # No delay for first juror\n",
    "                        time.sleep(random.uniform(2, 4))\n",
    "                \n",
    "                response = llm.invoke([HumanMessage(content=prompt)])\n",
    "                verdict_line = response.content.strip()\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                if \"429\" in error_msg or \"quota\" in error_msg.lower():\n",
    "                    if attempt < max_retries - 1:\n",
    "                        continue  # Retry with longer delay\n",
    "                    else:\n",
    "                        print(f\"‚ùå Rate limit exceeded collecting verdict from {jury_name}\")\n",
    "                        verdict_line = f\"VERDICT: NOT GUILTY - Unable to determine due to system limitations\"\n",
    "                else:\n",
    "                    print(f\"Error getting verdict from {jury_name}: {e}\")\n",
    "                    verdict_line = f\"VERDICT: NOT GUILTY - Unable to determine due to technical issue\"\n",
    "                break\n",
    "\n",
    "        verdicts[jury_name] = verdict_line\n",
    "\n",
    "    # Count votes\n",
    "    guilty_votes = sum(1 for v in verdicts.values() if \"GUILTY\" in v.upper() and \"NOT GUILTY\" not in v.upper())\n",
    "    not_guilty_votes = len(verdicts) - guilty_votes\n",
    "\n",
    "    # Final summary\n",
    "    summary = \"=== FINAL VERDICTS ===\\n\"\n",
    "    for jury_name, verdict in verdicts.items():\n",
    "        summary += f\"{jury_name}: {verdict}\\n\"\n",
    "\n",
    "    summary += f\"\\nFINAL TALLY: {guilty_votes} Guilty, {not_guilty_votes} Not Guilty\\n\"\n",
    "\n",
    "    if guilty_votes > not_guilty_votes:\n",
    "        summary += \"JURY DECISION: GUILTY\"\n",
    "    elif not_guilty_votes > guilty_votes:\n",
    "        summary += \"JURY DECISION: NOT GUILTY\"\n",
    "    else:\n",
    "        summary += \"JURY DECISION: HUNG JURY (TIE)\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=summary, name=\"Final_Verdict\")]\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.661934Z",
     "start_time": "2025-07-23T15:38:02.654374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_deliberation_summary(messages: List[BaseMessage], max_messages: int = 25) -> str:\n",
    "    \"\"\"Create a summary of key discussion points from the deliberation\"\"\"\n",
    "\n",
    "    # Filter out moderator announcements and get actual discussion\n",
    "    discussion_messages = []\n",
    "    for msg in messages:\n",
    "        if hasattr(msg, 'name'):\n",
    "            # # Skip moderator procedural messages\n",
    "            # if msg.name == \"Moderator\" and \"===\" in msg.content:\n",
    "            #     continue\n",
    "            # Skip the initial case presentation\n",
    "            if msg.name == \"User\":\n",
    "                continue\n",
    "            discussion_messages.append(f\"{msg.name}: {msg.content}\")\n",
    "\n",
    "    # Take the most recent discussion points\n",
    "    if len(discussion_messages) > max_messages:\n",
    "        discussion_messages = discussion_messages[-max_messages:]\n",
    "\n",
    "    return \"\\n\".join(discussion_messages)"
   ],
   "outputs": [],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzIrBhp9O4Cy"
   },
   "source": [
    "# Rounds"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1749654335065,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "FZfqe1zoROsm",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.703548Z",
     "start_time": "2025-07-23T15:38:02.694565Z"
    }
   },
   "source": [
    "def should_continue(state: JuryState):\n",
    "    \"\"\"Enhanced flow control for multi-round deliberations\"\"\"\n",
    "    current_round = state.get(\"current_round\", 0)\n",
    "    current_juror_index = state.get(\"current_juror_index\", 0)\n",
    "    total_rounds = state.get(\"total_rounds\", 3)\n",
    "    jury_order = state.get(\"jury_order\", [])\n",
    "\n",
    "    # If no jury order set, we're in trouble\n",
    "    if not jury_order:\n",
    "        return \"final_verdict\"\n",
    "\n",
    "    # If we've completed all rounds, go to final verdict\n",
    "    if current_round > total_rounds:\n",
    "        return \"final_verdict\"\n",
    "\n",
    "    # If this is the start (round 0), begin first round\n",
    "    if current_round == 0:\n",
    "        return \"start_round\"\n",
    "\n",
    "    # If we're in a valid round, determine next action\n",
    "    if current_juror_index < len(jury_order):\n",
    "        # Next juror should speak\n",
    "        return jury_order[current_juror_index]\n",
    "    else:\n",
    "        # All jurors have spoken in this round, start next round\n",
    "        return \"start_round\"\n"
   ],
   "outputs": [],
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335070,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "mNn8ZBPwO5b1",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.749068Z",
     "start_time": "2025-07-23T15:38:02.738808Z"
    }
   },
   "source": [
    "def start_round(state: JuryState):\n",
    "    \"\"\"Start a new round of deliberation\"\"\"\n",
    "    current_round = state.get(\"current_round\", 0) + 1\n",
    "    total_rounds = state.get(\"total_rounds\", 3)\n",
    "    jury_order = state.get(\"jury_order\", [])\n",
    "\n",
    "    # If we've completed all rounds, signal for final verdict\n",
    "    if current_round > total_rounds:\n",
    "        msg = AIMessage(content=\"=== COLLECTING FINAL VERDICTS ===\", name=\"Moderator\")\n",
    "        return {\n",
    "            \"messages\": [msg],\n",
    "            \"current_round\": current_round,\n",
    "            \"current_juror_index\": 0\n",
    "        }\n",
    "\n",
    "    # Announce the new round\n",
    "    msg = AIMessage(content=f\"=== DELIBERATION ROUND {current_round} ===\", name=\"Moderator\")\n",
    "\n",
    "    # Start new round with first juror\n",
    "    return {\n",
    "        \"messages\": [msg],\n",
    "        \"current_round\": current_round,\n",
    "        \"current_juror_index\": 0\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335076,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "O8r8guRIPN2f",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.792188Z",
     "start_time": "2025-07-23T15:38:02.785931Z"
    }
   },
   "source": [
    "def set_deliberation_rounds(total_rounds: int):\n",
    "    \"\"\"Set the number of deliberation rounds\"\"\"\n",
    "    global current_total_rounds\n",
    "    current_total_rounds = total_rounds\n",
    "    print(f\"Set deliberation to {total_rounds} rounds\")"
   ],
   "outputs": [],
   "execution_count": 120
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iw3BeXx6oCA"
   },
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749654335081,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "W_53OFhWPxcZ",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.841849Z",
     "start_time": "2025-07-23T15:38:02.833506Z"
    }
   },
   "source": [
    "def create_jury_graph(yaml_file: str = None, background_files: List[str] = None, total_rounds: int = 3):\n",
    "    \"\"\"Create the jury deliberation graph\n",
    "\n",
    "    Args:\n",
    "        yaml_file: Path to YAML file with jury member data\n",
    "        background_files: List of text files (for backward compatibility)\n",
    "        total_rounds: Number of deliberation rounds before final verdict\n",
    "    \"\"\"\n",
    "\n",
    "    # Load backgrounds - prioritize YAML file if provided\n",
    "    if yaml_file:\n",
    "        backgrounds = load_backgrounds_from_yaml(yaml_file)\n",
    "    elif background_files:\n",
    "        backgrounds = load_backgrounds_from_files(background_files)\n",
    "    else:\n",
    "        backgrounds = JURY_MEMBERS.copy()\n",
    "\n",
    "    workflow = StateGraph(JuryState)\n",
    "\n",
    "    # Add moderator, start_round, and final verdict nodes\n",
    "    workflow.add_node(\"moderator\", moderator)\n",
    "    workflow.add_node(\"start_round\", start_round)\n",
    "    workflow.add_node(\"final_verdict\", final_verdict)\n",
    "\n",
    "    # Add jury members\n",
    "    for jury_name in backgrounds.keys():\n",
    "        workflow.add_node(jury_name, create_jury_node(jury_name))\n",
    "\n",
    "    # Set up flow\n",
    "    workflow.add_edge(START, \"moderator\")\n",
    "    workflow.add_conditional_edges(\"moderator\", should_continue)\n",
    "\n",
    "    # start_round determines what happens next\n",
    "    workflow.add_conditional_edges(\"start_round\", should_continue)\n",
    "\n",
    "    # Each jury member goes back to flow control\n",
    "    for jury_name in backgrounds.keys():\n",
    "        workflow.add_conditional_edges(jury_name, should_continue)\n",
    "\n",
    "    # Final verdict goes to END\n",
    "    workflow.add_edge(\"final_verdict\", END)\n",
    "\n",
    "    return workflow.compile(), backgrounds, total_rounds"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wj2lxtG6sza"
   },
   "source": [
    "# Initialize graph\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1749654335086,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "3z7ksFnw3KA7",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.912927Z",
     "start_time": "2025-07-23T15:38:02.885660Z"
    }
   },
   "source": [
    "# Initialize graph\n",
    "graph, jury_backgrounds, default_rounds = create_jury_graph()"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j92-ptG6W55Z"
   },
   "source": [
    "# Stream graph updates"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1749654335122,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "64p5jpSOPULb",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:02.954152Z",
     "start_time": "2025-07-23T15:38:02.944074Z"
    }
   },
   "source": [
    "def stream_graph_updates(case_input: str = None, save_to_file: bool = True):\n",
    "    \"\"\"Stream jury deliberation updates and optionally save to markdown file\"\"\"\n",
    "    global deliberation_output, current_case_filename, current_scenario_number\n",
    "\n",
    "    if graph is None:\n",
    "        print(\"Cannot run deliberation - API key not configured\")\n",
    "        return\n",
    "\n",
    "    # Use provided case or current loaded case\n",
    "    if case_input is None:\n",
    "        if current_case is None:\n",
    "            print(\"No case provided and no case loaded from file\")\n",
    "            return\n",
    "        case_input = current_case\n",
    "    else:\n",
    "        # If case is provided directly, reset file tracking\n",
    "        if case_input != current_case:\n",
    "            current_case_filename = None\n",
    "            current_scenario_number = None\n",
    "\n",
    "    # Clear previous output and prepare for new deliberation\n",
    "    deliberation_output = []\n",
    "\n",
    "    # Create jury order from backgrounds\n",
    "    jury_order = list(jury_backgrounds.keys())\n",
    "    juror_colors = assign_juror_colors(jury_order)\n",
    "\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=case_input)],\n",
    "        \"case_details\": case_input,\n",
    "        \"jury_backgrounds\": jury_backgrounds,\n",
    "        \"current_round\": 0,\n",
    "        \"current_juror_index\": 0,\n",
    "        \"total_rounds\": current_total_rounds,\n",
    "        \"jury_order\": jury_order\n",
    "    }\n",
    "\n",
    "    # Process the deliberation\n",
    "    for event in graph.stream(initial_state):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and value[\"messages\"]:\n",
    "                last_message = value[\"messages\"][-1]\n",
    "                speaker = getattr(last_message, 'name', 'System')\n",
    "                content = last_message.content\n",
    "\n",
    "                # Print to console\n",
    "                print(f\"{speaker}: {content}\")\n",
    "                print()\n",
    "\n",
    "                # Format and store for markdown file\n",
    "                if save_to_file:\n",
    "                    formatted_output = format_speaker_output(speaker, content, juror_colors)\n",
    "                    deliberation_output.append(formatted_output)\n",
    "\n",
    "    # Save to markdown file if requested\n",
    "    if save_to_file and deliberation_output:\n",
    "        save_deliberation_to_markdown(case_input, deliberation_output)"
   ],
   "outputs": [],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-O_95FlAWlf4"
   },
   "source": [
    "# Save output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749654335124,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "fscMYQ2AWmsN",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:03.004011Z",
     "start_time": "2025-07-23T15:38:02.994247Z"
    }
   },
   "source": [
    "# Global variables for output capturing and file tracking\n",
    "current_case = None\n",
    "current_total_rounds = default_rounds\n",
    "deliberation_output = []  # Store all output for saving to file\n",
    "current_jury_filename = None\n",
    "current_case_filename = None\n",
    "current_scenario_number = None\n",
    "\n",
    "# Create temporary download directory (similar to upload directory setup)\n",
    "DOWNLOAD_DIR = tempfile.mkdtemp(prefix=\"jury_downloads_\")\n",
    "print(f\"Download directory: {DOWNLOAD_DIR}\")\n",
    "\n",
    "# Color mapping for different speakers\n",
    "SPEAKER_COLORS = {\n",
    "    \"Moderator\": \"#2E8B57\",      # Sea Green\n",
    "    \"Final_Verdict\": \"#8B0000\",   # Dark Red\n",
    "    # Default juror colors (will be assigned dynamically)\n",
    "    \"default_colors\": [\n",
    "        \"#4169E1\",  # Royal Blue\n",
    "        \"#DC143C\",  # Crimson\n",
    "        \"#FF8C00\",  # Dark Orange\n",
    "        \"#9932CC\",  # Dark Orchid\n",
    "        \"#228B22\",  # Forest Green\n",
    "        \"#FF1493\",  # Deep Pink\n",
    "        \"#8B4513\",  # Saddle Brown\n",
    "        \"#00CED1\",  # Dark Turquoise\n",
    "    ]\n",
    "}"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download directory: C:\\Users\\user\\AppData\\Local\\Temp\\jury_downloads_ah8i6isg\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1749654335156,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "kNs8LA2inIJ_",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:03.104558Z",
     "start_time": "2025-07-23T15:38:03.087816Z"
    }
   },
   "source": [
    "def assign_juror_colors(jury_names):\n",
    "    \"\"\"Assign colors to jury members\"\"\"\n",
    "    colors = {}\n",
    "    available_colors = SPEAKER_COLORS[\"default_colors\"]\n",
    "\n",
    "    for i, name in enumerate(jury_names):\n",
    "        if i < len(available_colors):\n",
    "            colors[name] = available_colors[i]\n",
    "        else:\n",
    "            # If more jurors than colors, cycle through\n",
    "            colors[name] = available_colors[i % len(available_colors)]\n",
    "\n",
    "    return colors\n",
    "\n",
    "def format_speaker_output(speaker, content, juror_colors):\n",
    "    \"\"\"Format speaker output with colors for markdown\"\"\"\n",
    "    if speaker in juror_colors:\n",
    "        color = juror_colors[speaker]\n",
    "    elif speaker in SPEAKER_COLORS:\n",
    "        color = SPEAKER_COLORS[speaker]\n",
    "    else:\n",
    "        color = \"#000000\"  # Default black\n",
    "\n",
    "    return f'<span style=\"color: {color}\"><strong>{speaker}:</strong></span> {content}'\n",
    "\n",
    "def clean_filename_for_output(filepath):\n",
    "    \"\"\"Extract clean filename without extension and path\"\"\"\n",
    "    if filepath is None:\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Get just the filename without path\n",
    "    filename = filepath.split('/')[-1].split('\\\\')[-1]\n",
    "\n",
    "    # Remove extension\n",
    "    filename = filename.rsplit('.', 1)[0]\n",
    "\n",
    "    # Replace spaces and special characters with underscores\n",
    "    filename = filename.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remove any non-alphanumeric characters except underscores\n",
    "    filename = re.sub(r'[^a-zA-Z0-9_]', '', filename)\n",
    "\n",
    "    return filename\n",
    "\n",
    "def save_deliberation_to_markdown(case_details, output_list, filename=None):\n",
    "    \"\"\"Save deliberation output to a markdown file with enhanced naming\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        # Build filename components\n",
    "        jury_part = clean_filename_for_output(current_jury_filename) if current_jury_filename else \"default_jury\"\n",
    "        case_part = clean_filename_for_output(current_case_filename) if current_case_filename else \"direct_case\"\n",
    "        scenario_part = f\"scenario{current_scenario_number}\" if current_scenario_number else \"full\"\n",
    "\n",
    "        filename = f\"deliberation_{jury_part}_{case_part}_{scenario_part}_{timestamp}.md\"\n",
    "\n",
    "    # Save to download directory instead of current directory\n",
    "    full_filepath = os.path.join(DOWNLOAD_DIR, filename)\n",
    "\n",
    "    # Create markdown content\n",
    "    markdown_content = f\"\"\"# Jury Deliberation Report\n",
    "\n",
    "**Generated on:** {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "**Configuration:**\n",
    "- Jury File: {current_jury_filename or \"Default jury members\"}\n",
    "- Case File: {current_case_filename or \"Direct input\"}\n",
    "- Scenario: {current_scenario_number if current_scenario_number else \"Full case\"}\n",
    "- Rounds: {current_total_rounds}\n",
    "\n",
    "## Case Details\n",
    "\n",
    "{case_details}\n",
    "\n",
    "---\n",
    "\n",
    "## Deliberation Process\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Add all the captured output\n",
    "    for line in output_list:\n",
    "        markdown_content += line + \"\\n\\n\"\n",
    "\n",
    "    # Add color legend\n",
    "    markdown_content += \"\\n---\\n\\n## Color Legend\\n\\n\"\n",
    "\n",
    "    # Get current juror colors\n",
    "    jury_names = list(jury_backgrounds.keys()) if jury_backgrounds else []\n",
    "    juror_colors = assign_juror_colors(jury_names)\n",
    "\n",
    "    # Add Moderator and Final Verdict to legend\n",
    "    all_colors = {**juror_colors, **SPEAKER_COLORS}\n",
    "\n",
    "    for speaker, color in all_colors.items():\n",
    "        if speaker != \"default_colors\":\n",
    "            markdown_content += f'<span style=\"color: {color}\"><strong>{speaker}</strong></span>\\n\\n'\n",
    "\n",
    "    # Save to file\n",
    "    try:\n",
    "        with open(full_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(markdown_content)\n",
    "        print(f\"üìÑ Deliberation saved to: {full_filepath}\")\n",
    "        return full_filepath\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving deliberation: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_download_directory():\n",
    "    \"\"\"Get the download directory path for external access (e.g., Flask app)\"\"\"\n",
    "    return DOWNLOAD_DIR\n",
    "\n",
    "def list_download_files():\n",
    "    \"\"\"List all files available in the download directory\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(DOWNLOAD_DIR):\n",
    "            files = [f for f in os.listdir(DOWNLOAD_DIR) if f.endswith('.md')]\n",
    "            return [(f, os.path.join(DOWNLOAD_DIR, f)) for f in sorted(files, reverse=True)]\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error listing download files: {e}\")\n",
    "        return []\n"
   ],
   "outputs": [],
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwLHmMYn74Cc"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKLqt3QjaQb7"
   },
   "source": [
    "## Main interaction loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1749654335164,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "jHuRltOzJVuQ",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:03.163196Z",
     "start_time": "2025-07-23T15:38:03.146006Z"
    }
   },
   "source": [
    "# Main interaction loop\n",
    "def main(interactive: bool = False, save_to_file: bool = True):\n",
    "    \"\"\"Main function to run jury deliberation\n",
    "\n",
    "    Args:\n",
    "        interactive: If True, runs interactive mode. If False, auto-runs with loaded case.\n",
    "        save_to_file: Whether to save deliberation to markdown file\n",
    "    \"\"\"\n",
    "    print(\"=== JURY DELIBERATION SIMULATION ===\")\n",
    "\n",
    "    # Check if LLM is properly initialized\n",
    "    if llm is None:\n",
    "        print(\"\\n‚ùå SETUP REQUIRED:\")\n",
    "        print(\"1. Get a free API key from: https://aistudio.google.com/app/apikey\")\n",
    "        print(\"2. Set the environment variable:\")\n",
    "        print(\"   export GOOGLE_API_KEY='your-api-key-here'\")\n",
    "        print(\"   (or set it in your script/notebook)\")\n",
    "        print(\"\\nExiting...\")\n",
    "        return\n",
    "\n",
    "    # If case is pre-loaded and not in interactive mode, run automatically\n",
    "    if not interactive and current_case is not None:\n",
    "        print(\"üöÄ Auto-starting deliberation with pre-loaded case and jury...\")\n",
    "        print(f\"\\nJury Members: {list(jury_backgrounds.keys())}\")\n",
    "        print(f\"Deliberation Rounds: {current_total_rounds}\")\n",
    "        print(f\"\\nCase: {current_case}\\n\")\n",
    "        print(\"üèõÔ∏è Starting deliberation...\\n\")\n",
    "        stream_graph_updates(save_to_file=save_to_file)\n",
    "        print(\"\\nüèÅ Deliberation completed!\")\n",
    "        return\n",
    "\n",
    "    # # Interactive mode\n",
    "    # if interactive:\n",
    "    #   print(\"Commands:\")\n",
    "    #   print(\"‚Ä¢ 'load <yaml_file>' - Load jury members from YAML file\")\n",
    "    #   print(\"‚Ä¢ 'load <yaml_file> <rounds>' - Load jury members and set rounds\")\n",
    "    #   print(\"‚Ä¢ 'rounds <number>' - Set number of deliberation rounds\")\n",
    "    #   print(\"‚Ä¢ 'case <case_file>' - Load case from text file\")\n",
    "    #   print(\"‚Ä¢ 'case <case_file> <scenario_number>' - Load specific scenario from file\")\n",
    "    #   print(\"‚Ä¢ 'scenarios <case_file>' - List available scenarios in file\")\n",
    "    #   print(\"‚Ä¢ 'deliberate' - Start deliberation with loaded case\")\n",
    "    #   print(\"‚Ä¢ 'deliberate nosave' - Start deliberation without saving to file\")\n",
    "    #   print(\"‚Ä¢ 'quit', 'exit', or 'q' - Stop\")\n",
    "    #   print(\"‚Ä¢ Or type case details directly for immediate deliberation\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"Enter command or case details: \")\n",
    "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "\n",
    "            # Check if user wants to load YAML file\n",
    "            if user_input.lower().startswith(\"load \"):\n",
    "                parts = user_input[5:].strip().split()\n",
    "                yaml_file = parts[0]\n",
    "                rounds = int(parts[1]) if len(parts) > 1 else 3\n",
    "\n",
    "                try:\n",
    "                    initialize_with_yaml(yaml_file, rounds)\n",
    "                    print(\"Jury members loaded successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading YAML file: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to set rounds\n",
    "            if user_input.lower().startswith(\"rounds \"):\n",
    "                try:\n",
    "                    rounds = int(user_input[7:].strip())\n",
    "                    set_deliberation_rounds(rounds)\n",
    "                except ValueError:\n",
    "                    print(\"Invalid number of rounds. Please enter a number.\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to load case file\n",
    "            if user_input.lower().startswith(\"case \"):\n",
    "                parts = user_input[5:].strip().split()\n",
    "                case_file = parts[0]\n",
    "                scenario_num = int(parts[1]) if len(parts) > 1 else None\n",
    "\n",
    "                try:\n",
    "                    initialize_with_case(case_file, scenario_num)\n",
    "                    print(\"Case loaded successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading case file: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to list scenarios\n",
    "            if user_input.lower().startswith(\"scenarios \"):\n",
    "                case_file = user_input[10:].strip()\n",
    "                scenarios = list_scenarios_in_file(case_file)\n",
    "                if scenarios:\n",
    "                    print(f\"Available scenarios in {case_file}:\")\n",
    "                    for num, title in scenarios:\n",
    "                        print(f\"  {num}: {title}\")\n",
    "                else:\n",
    "                    print(\"No scenarios found or file error\")\n",
    "                continue\n",
    "\n",
    "            # Check if user wants to deliberate with loaded case\n",
    "            if user_input.lower().startswith(\"deliberate\"):\n",
    "                if current_case is None:\n",
    "                    print(\"No case loaded. Use 'case <filename>' to load a case first.\")\n",
    "                    continue\n",
    "\n",
    "                # Check if user wants to save or not\n",
    "                save_file = \"nosave\" not in user_input.lower()\n",
    "\n",
    "                print(f\"\\nüèõÔ∏è Starting deliberation with loaded case...\\n\")\n",
    "                stream_graph_updates(save_to_file=save_file)\n",
    "                print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "                continue\n",
    "\n",
    "            # Treat as direct case input for immediate deliberation\n",
    "            if user_input.strip():\n",
    "                print(f\"\\nCase: {user_input}\\n\")\n",
    "                stream_graph_updates(user_input, save_to_file=save_to_file)\n",
    "                print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Trying with fallback example...\")\n",
    "            # Fallback example\n",
    "            user_input = \"John stole a laptop worth $1200 from a coffee shop. He was caught with it 3 days later but claims he bought it from someone on the street for $300. He has no prior record but recently lost his job.\"\n",
    "            print(\"Case: \" + user_input)\n",
    "            stream_graph_updates(user_input, save_to_file=save_to_file)\n",
    "            break"
   ],
   "outputs": [],
   "execution_count": 126
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7OiVx0maSRP"
   },
   "source": [
    "## `run_deliberation` function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749654335167,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "7wU3XctXJLsb",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:03.216199Z",
     "start_time": "2025-07-23T15:38:03.206392Z"
    }
   },
   "source": [
    "def run_deliberation(jury_file: str = None, case_file: str = None, scenario_number: int = None, total_rounds: int = 3, save_to_file: bool = True):\n",
    "    \"\"\"Convenience function to run a complete deliberation session\n",
    "\n",
    "    Args:\n",
    "        jury_file: Path to YAML file with jury members\n",
    "        case_file: Path to text file with case details\n",
    "        scenario_number: If case file has multiple scenarios, specify which one\n",
    "        total_rounds: Number of deliberation rounds before final verdict\n",
    "        save_to_file: Whether to save deliberation to markdown file\n",
    "    \"\"\"\n",
    "    print(\"=== AUTOMATED JURY DELIBERATION ===\")\n",
    "\n",
    "    if llm is None:\n",
    "        print(\"‚ùå API key not configured. Cannot run deliberation.\")\n",
    "        return\n",
    "\n",
    "    # Load jury members if specified\n",
    "    if jury_file:\n",
    "        try:\n",
    "            initialize_with_yaml(jury_file, total_rounds)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading jury file: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        # Set rounds even if no jury file specified\n",
    "        set_deliberation_rounds(total_rounds)\n",
    "\n",
    "    # Load case if specified\n",
    "    if case_file:\n",
    "        try:\n",
    "            initialize_with_case(case_file, scenario_number)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading case file: {e}\")\n",
    "            return\n",
    "\n",
    "    # Run deliberation\n",
    "    if current_case is None:\n",
    "        print(\"‚ùå No case loaded. Cannot start deliberation.\")\n",
    "        return\n",
    "\n",
    "    print(\"üöÄ Starting automated deliberation...\")\n",
    "    print(f\"\\nJury Members: {list(jury_backgrounds.keys())}\")\n",
    "    print(f\"Deliberation Rounds: {current_total_rounds}\")\n",
    "    print(f\"\\nCase Preview: {current_case[:200]}{'...' if len(current_case) > 200 else ''}\\n\")\n",
    "    print(\"üèõÔ∏è Beginning deliberation...\\n\")\n",
    "\n",
    "    stream_graph_updates(save_to_file=save_to_file)\n",
    "    print(\"\\nüèÅ Deliberation completed!\")\n"
   ],
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJNwg9aGaVw_"
   },
   "source": [
    "## Run `main`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1749654335193,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "9h4tcX_u6Nkq",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:45.081918Z",
     "start_time": "2025-07-23T15:38:03.276620Z"
    }
   },
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#\n",
    "#     initialize_with_yaml(\"jurors/jurors.yaml\", total_rounds=3)\n",
    "#     initialize_with_case(case_file_path=\"cases/Scenario 1.txt\", scenario_number=2)\n",
    "#\n",
    "#     # Display graph visualization\n",
    "#     # try:\n",
    "#     #     print(\"Graph structure:\")\n",
    "#     #     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "#     # except Exception as e:\n",
    "#     #     print(f\"Could not display graph: {e}\")\n",
    "#\n",
    "#     print(\"\\n\")\n",
    "#     main(interactive=False, save_to_file=False)  # Auto-run with pre-loaded case"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded jury members from jurors/jurors.yaml:\n",
      "  - Casey Brown\n",
      "  - Mitchell Johnson\n",
      "  - Heather Perez\n",
      "Set to 3 deliberation rounds\n",
      "\n",
      "‚úÖ Loaded Scenario 2 from cases/Scenario 1.txt\n",
      "Case Preview: Scenario 2: \n",
      "Background: Tomer and Stan are accused of murder. The prosecution claims they were the only ones seen in the store shortly before the murder and fleeing the scene afterward.\n",
      "Presenting th...\n",
      "\n",
      "\n",
      "\n",
      "=== JURY DELIBERATION SIMULATION ===\n",
      "üöÄ Auto-starting deliberation with pre-loaded case and jury...\n",
      "\n",
      "Jury Members: ['Casey Brown', 'Mitchell Johnson', 'Heather Perez']\n",
      "Deliberation Rounds: 3\n",
      "\n",
      "Case: Scenario 2: \n",
      "Background: Tomer and Stan are accused of murder. The prosecution claims they were the only ones seen in the store shortly before the murder and fleeing the scene afterward.\n",
      "Presenting the Decisive Evidence: The trial is underway. The prosecution has presented the Sheriff's testimony confirming that Tomer and Stan were identified at the scene and fled, along with eyewitness testimonies. The Sheriff also testified that there was no active security camera in the store.\n",
      "Presenting the Defense's Evidence: Inbar, the lawyer, calls Mr. Alon, the manager of a neighboring convenience store located across the street, to the witness stand. Inbar: \"Mr. Alon, how long have you managed 'the tasty honey' store?\" Mr. Alon: \"About 15 years, Your Honor.\" Inbar: \"Are there security cameras outside your store?\" Mr. Alon: \"Yes, I have a camera that films the main road and the entrance to my store, for security reasons.\" Inbar: \"And on the morning of the incident, around 11:00 AM, was this camera active?\" Mr. Alon: \"Yes, it's always active.\" Inbar: \"Did you check the footage from that morning?\" Mr. Alon: \"Absolutely. The police asked, but they didn't see anything unusual there.\" Inbar: \"Your Honor, I would like to present to the court security footage received from Mr. Alon. The footage shows the time when Tomer and Stan left the 'Sac-O-Suds' store.\" The video is projected onto a large screen. Tomer and Stan's car is clearly seen driving away. A few seconds later, another person, who is neither Tomer nor Stan, is seen hastily exiting the nearby \"Sac-O-Suds\" store. Their face is not completely clear due to the distance, but it is clear that this is a completely different person. They get into a black car parked on the other side of the road and drive away quickly. Inbar: \"Mr. Alon, is the person we saw in the video exiting the 'Sac-O-Suds' store one of the two defendants sitting here?\" Mr. Alon: \"No, sir. It's not them.\" Inbar: \"Your Honor, please note: this video clearly proves that Tomer and Stan left the scene before the murder was committed, and that another person, unrelated to them, exited the store shortly thereafter. This indicates that another person is the killer.\" Inbar: \"In light of the video, the Sheriff will need to re-investigate the eyewitness testimonies and examine the precise timing of the events.\"\n",
      "\n",
      "üèõÔ∏è Starting deliberation...\n",
      "\n",
      "Moderator: === JURY DELIBERATION BEGINS ===\n",
      "\n",
      "Moderator: === DELIBERATION ROUND 1 ===\n",
      "\n",
      "Casey Brown: Alright, alright, let's get this over with. That video definitely throws a wrench in things. If someone else was seen leaving the store right after, it's hard to say for sure Tomer and Stan did it.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the new video evidence presented by the defense.]\n",
      "\n",
      "Mitchell Johnson: Well, I agree with Casey, that video changes everything. The Sheriff's testimony and eyewitnesses are important, but this new evidence introduces reasonable doubt. We need to consider that other person leaving the store.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence showing another person leaving the store.]\n",
      "\n",
      "Heather Perez: Well, now hold on a minute, folks. This video *is* interesting, I'll grant you that. But are we absolutely sure about the timing? And that the other person *definitely* committed the murder? I think we need to really dig into the details here, maybe even re-watch that video a few more times before we rush to any conclusions.\n",
      "\n",
      "[Current stance: GUILTY] - [Need to examine the details of the video more closely before making a decision.]\n",
      "\n",
      "Moderator: === DELIBERATION ROUND 2 ===\n",
      "\n",
      "Casey Brown: Look, I hear Heather, but honestly, how much more digging do we need? The video shows someone else leaving the store right after Tomer and Stan. That's enough doubt for me, I'm ready to move on.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt.]\n",
      "\n",
      "Mitchell Johnson: I agree with Heather that we shouldn't rush to a decision, but Casey has a point too. That video is pretty compelling, and it's hard to ignore the fact that someone else was seen leaving the store right after Tomer and Stan. I think we need to watch the video again, focusing on the timing and trying to get a better look at that other person.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt, but needs further review]\n",
      "\n",
      "Heather Perez: Alright, alright, settle down everyone. I understand the video is compelling, but let's not get ahead of ourselves. We need to consider the lighting, the angle, the *everything*! I think we should request a transcript of Mr. Alon's testimony and compare it to the video's timestamp. We need to be absolutely certain before we make such a big decision.\n",
      "\n",
      "[Current stance: GUILTY] - [Need to examine the details of the video and testimony more closely before making a decision.]\n",
      "\n",
      "Moderator: === DELIBERATION ROUND 3 ===\n",
      "\n",
      "Casey Brown: Alright, alright, I get what Heather's saying about the details, but come on, we're splitting hairs here. The video shows someone else leaving the scene, that's good enough for me. Let's just call it a day and get out of here.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt and wanting to end the deliberation.]\n",
      "\n",
      "Mitchell Johnson: Okay, folks, I understand Heather's caution, but I also see Casey's point about the video being pretty strong evidence. I think watching the video again, like I said before, is a good idea, but I also think Heather's suggestion of getting a transcript of Mr. Alon's testimony is smart - we need to be thorough.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt, but supporting further review of the evidence.]\n",
      "\n",
      "Heather Perez: Well, I'm glad Mitchell agrees with me about the transcript! Honestly, I think we should also request the Sheriff's full report and compare *that* to the video. We need to be absolutely certain we're not missing anything before we let these two off the hook.\n",
      "\n",
      "[Current stance: GUILTY] - [Need to examine all the evidence thoroughly before making a decision.]\n",
      "\n",
      "Moderator: === COLLECTING FINAL VERDICTS ===\n",
      "\n",
      "Casey Brown: Alright, alright, let's get this over with. That video definitely throws a wrench in things. If someone else was seen leaving the store right after, it's hard to say for sure Tomer and Stan did it.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the new video evidence presented by the defense.]\n",
      "Mitchell Johnson: Well, I agree with Casey, that video changes everything. The Sheriff's testimony and eyewitnesses are important, but this new evidence introduces reasonable doubt. We need to consider that other person leaving the store.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence showing another person leaving the store.]\n",
      "Heather Perez: Well, now hold on a minute, folks. This video *is* interesting, I'll grant you that. But are we absolutely sure about the timing? And that the other person *definitely* committed the murder? I think we need to really dig into the details here, maybe even re-watch that video a few more times before we rush to any conclusions.\n",
      "\n",
      "[Current stance: GUILTY] - [Need to examine the details of the video more closely before making a decision.]\n",
      "Casey Brown: Look, I hear Heather, but honestly, how much more digging do we need? The video shows someone else leaving the store right after Tomer and Stan. That's enough doubt for me, I'm ready to move on.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt.]\n",
      "Mitchell Johnson: I agree with Heather that we shouldn't rush to a decision, but Casey has a point too. That video is pretty compelling, and it's hard to ignore the fact that someone else was seen leaving the store right after Tomer and Stan. I think we need to watch the video again, focusing on the timing and trying to get a better look at that other person.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt, but needs further review]\n",
      "Heather Perez: Alright, alright, settle down everyone. I understand the video is compelling, but let's not get ahead of ourselves. We need to consider the lighting, the angle, the *everything*! I think we should request a transcript of Mr. Alon's testimony and compare it to the video's timestamp. We need to be absolutely certain before we make such a big decision.\n",
      "\n",
      "[Current stance: GUILTY] - [Need to examine the details of the video and testimony more closely before making a decision.]\n",
      "Casey Brown: Alright, alright, I get what Heather's saying about the details, but come on, we're splitting hairs here. The video shows someone else leaving the scene, that's good enough for me. Let's just call it a day and get out of here.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt and wanting to end the deliberation.]\n",
      "Mitchell Johnson: Okay, folks, I understand Heather's caution, but I also see Casey's point about the video being pretty strong evidence. I think watching the video again, like I said before, is a good idea, but I also think Heather's suggestion of getting a transcript of Mr. Alon's testimony is smart - we need to be thorough.\n",
      "\n",
      "[Current stance: NOT GUILTY] - [Due to the video evidence creating reasonable doubt, but supporting further review of the evidence.]\n",
      "Heather Perez: Well, I'm glad Mitchell agrees with me about the transcript! Honestly, I think we should also request the Sheriff's full report and compare *that* to the video. We need to be absolutely certain we're not missing anything before we let these two off the hook.\n",
      "\n",
      "[Current stance: GUILTY] - [Need to examine all the evidence thoroughly before making a decision.]\n",
      "Final_Verdict: === FINAL VERDICTS ===\n",
      "Casey Brown: VERDICT: NOT GUILTY - The video evidence of another person leaving the scene creates reasonable doubt, and I'm ready to be done with this case.\n",
      "Mitchell Johnson: VERDICT: NOT GUILTY - The video evidence of another person leaving the scene creates reasonable doubt, despite the initial eyewitness testimonies and the Sheriff's report.\n",
      "Heather Perez: VERDICT: GUILTY - I still have lingering doubts and believe we need to examine all the evidence meticulously, even if it prolongs the process.\n",
      "\n",
      "FINAL TALLY: 1 Guilty, 2 Not Guilty\n",
      "JURY DECISION: NOT GUILTY\n",
      "\n",
      "\n",
      "üèÅ Deliberation completed!\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MahhJjofgGLP"
   },
   "source": [
    "## Run `run_deliberation`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8721,
     "status": "ok",
     "timestamp": 1749654343919,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "bx2KnUlXoOcn",
    "outputId": "89af5b9d-c28c-46d3-c1c9-411303753576",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:45.128928Z",
     "start_time": "2025-07-23T15:38:45.123928Z"
    }
   },
   "source": [
    "# Commented out - this was interfering with Flask app calls\n",
    "# run_deliberation(jury_file='republican_and_democratic.yaml',\n",
    "#                      case_file=\"Scenario 1.txt\",\n",
    "#                      scenario_number=1,\n",
    "#                      total_rounds=3,\n",
    "#                      save_to_file=True)"
   ],
   "outputs": [],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdpP5ZRhi_o0"
   },
   "source": [
    "# All test simulations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1749654343953,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "ONiGOLeujEFi",
    "outputId": "435b476e-3625-428e-ef4e-dab63dff0e70",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:45.187359Z",
     "start_time": "2025-07-23T15:38:45.179777Z"
    }
   },
   "source": [
    "# jurors_files = [file for file in  os.listdir() if file.endswith('.yaml')]\n",
    "# print(jurors_files)"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1749654343964,
     "user": {
      "displayName": "Omri Sgan Cohen",
      "userId": "05883219044632245474"
     },
     "user_tz": -180
    },
    "id": "O5_shv--jBt1",
    "ExecuteTime": {
     "end_time": "2025-07-23T15:38:45.247763Z",
     "start_time": "2025-07-23T15:38:45.240643Z"
    }
   },
   "source": [
    "# for jurors_yaml_file in jurors_files:\n",
    "#   for scenarion_num in range(1, 4):\n",
    "\n",
    "#     print(f\"=== {jurors_yaml_file} ===\")\n",
    "\n",
    "#     # initialize_with_yaml(jurors_yaml_file, total_rounds=3)\n",
    "#     # initialize_with_case(case_file_path=\"Scenario 1.txt\", scenario_number=scenarion_num)\n",
    "#     # print(\"\\n\")\n",
    "#     # main(interactive=False, save_to_file=True)  # Auto-run with pre-loaded case\n",
    "\n",
    "#     run_deliberation(jury_file=jurors_yaml_file,\n",
    "#                      case_file=\"Scenario 1.txt\",\n",
    "#                      scenario_number=scenarion_num,\n",
    "#                      total_rounds=3,\n",
    "#                      save_to_file=True)"
   ],
   "outputs": [],
   "execution_count": 131
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
