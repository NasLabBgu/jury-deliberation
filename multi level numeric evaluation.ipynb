{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The input is the .txt output from the simulation in https://jury-deliberation-app-prp3y5oy5a-zf.a.run.app/\n",
        "\n",
        "ADD THE FILE PATH"
      ],
      "metadata": {
        "id": "LBEosIpk8Pyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ―― path to your log file ―――――――――――――――――――――――――――――――\n",
        "file_path = \"/content/[STARTED] Starting 1 deliberation r.txt\""
      ],
      "metadata": {
        "id": "wr8SC2Ll8ku4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parses a jury‑simulation log file and returns a list—one item per run—where each item is a dictionary mapping every juror to their chronological [\"comment\", \"stance\"] pairs.\n",
        " ** The final comment and stance are the final verdict of the juror in a specific run !! **\n",
        "\n",
        "Shape of the output:\n",
        "[\n",
        "  {                       # Run 1\n",
        "    \"Juror A\": [[\"…\", \"UNDECIDED\"], [\"…\", \"GUILTY\"]],\n",
        "    \"Juror B\": [[\"…\", \"UNDECIDED\"], [\"…\", \"NOT GUILTY\"]],\n",
        "    …\n",
        "  },\n",
        "  { … },                  # Run 2\n",
        "  …\n",
        "]\n",
        "\"\"\"\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "# ───────────────────────────────────────────────────────────\n",
        "\n",
        "# regex helpers\n",
        "RUN_HDR        = re.compile(r\"^=== Run \\d+/\\d+\")\n",
        "DELIB_BEGIN    = \"=== JURY DELIBERATION BEGINS\"\n",
        "COLLECT_FINAL  = \"=== COLLECTING FINAL VERDICTS\"\n",
        "FINAL_HDR      = \"=== FINAL VERDICTS\"\n",
        "COMMENT_RE     = re.compile(r\"^\\s*([^:\\n]+):\\s*(.*)\")\n",
        "STANCE_RE      = re.compile(r\"^\\[Current stance:\\s*([A-Z ]+)\\]\\s*$\")\n",
        "EXCLUDE_NAMES  = {\n",
        "    \"moderator\", \"final verdict\", \"final_verdict\",\n",
        "    \"final tally\", \"jury decision\"\n",
        "}\n",
        "\n",
        "# ―― helpers ――――――――――――――――――――――――――――――――――――――――――――\n",
        "def _split_runs(lines: List[str]) -> List[List[str]]:\n",
        "    idxs = [i for i, ln in enumerate(lines) if RUN_HDR.match(ln)]\n",
        "    return [lines] if not idxs else [\n",
        "        lines[s:e] for s, e in zip(idxs, idxs[1:] + [len(lines)])\n",
        "    ]\n",
        "\n",
        "def _parse_single_run(chunk: List[str]) -> Dict[str, List[List[str]]]:\n",
        "    jurors: Dict[str, List[List[str]]] = {}\n",
        "\n",
        "    # boundaries of deliberation\n",
        "    try:\n",
        "        start = next(i for i, ln in enumerate(chunk) if DELIB_BEGIN in ln) + 1\n",
        "    except StopIteration:\n",
        "        return jurors\n",
        "    end = next(\n",
        "        (i for i, ln in enumerate(chunk[start:], start) if COLLECT_FINAL in ln),\n",
        "        len(chunk),\n",
        "    )\n",
        "\n",
        "    # deliberation rounds\n",
        "    i = start\n",
        "    while i < end:\n",
        "        ln = chunk[i]\n",
        "        if ln.lstrip().startswith(\"[\"):                 # skip stance‑only lines\n",
        "            i += 1; continue\n",
        "        if (m := COMMENT_RE.match(ln)):\n",
        "            name, text = m.group(1).strip(), m.group(2).strip()\n",
        "            if name.lower() in EXCLUDE_NAMES or name.startswith(\"[\"):\n",
        "                i += 1; continue\n",
        "            # look‑ahead for stance\n",
        "            stance = None\n",
        "            j = i + 1\n",
        "            while j < end:\n",
        "                if (sm := STANCE_RE.match(chunk[j])):\n",
        "                    stance = sm.group(1).strip(); break\n",
        "                if COMMENT_RE.match(chunk[j]) or \"Moderator:\" in chunk[j]:\n",
        "                    break\n",
        "                j += 1\n",
        "            jurors.setdefault(name, []).append([text, stance])\n",
        "        i += 1\n",
        "\n",
        "    # final verdicts\n",
        "    try:\n",
        "        fv_start = next(i for i, ln in enumerate(chunk) if FINAL_HDR in ln) + 1\n",
        "    except StopIteration:\n",
        "        fv_start = None\n",
        "\n",
        "    if fv_start is not None:\n",
        "        for ln in chunk[fv_start:]:\n",
        "            if not ln.strip():\n",
        "                continue\n",
        "            m = COMMENT_RE.match(ln)\n",
        "            if not m:\n",
        "                break\n",
        "            name, rest = m.group(1).strip(), m.group(2).strip()\n",
        "            if name.lower() in EXCLUDE_NAMES:\n",
        "                continue\n",
        "            stance_m = re.search(r\"\\b(GUILTY|NOT GUILTY|UNDECIDED)\\b\",\n",
        "                                 rest, re.I)\n",
        "            if not stance_m:\n",
        "                continue\n",
        "            stance = stance_m.group(1).upper()\n",
        "            comment = rest[stance_m.end():].lstrip(\":- \").strip()\n",
        "            comment = re.sub(r\"^VERDICT:\\s*\", \"\", comment, flags=re.I)\n",
        "            jurors.setdefault(name, []).append([comment, stance])\n",
        "\n",
        "    return jurors\n",
        "\n",
        "def parse_jury_log(path: str | Path) -> List[Dict[str, List[List[str]]]]:\n",
        "    \"\"\"\n",
        "    Parse one log file and return a *list*.\n",
        "    • Each list element corresponds to a run in the log, in order.\n",
        "    • Every element is {juror: [[comment, stance], …]}.\n",
        "    \"\"\"\n",
        "    lines = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
        "    runs = _split_runs(lines)\n",
        "    return [_parse_single_run(r) for r in runs if r]\n",
        "\n",
        "# ―― run & inspect ――――――――――――――――――――――――――――――――――――\n",
        "runs_data = parse_jury_log(file_path)\n",
        "runs_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEtJveEnsUAJ",
        "outputId": "402bc1c2-8156-49ea-cd69-1e197037234a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Michelle Chavez': [[\"Well, that defense lawyer sure did a number on Mrs. Cohen. If she couldn't even read the newspaper, how could she be sure she saw Tomer and Stan? It makes me question the whole case.\",\n",
              "    'UNDECIDED'],\n",
              "   [\"The eyewitness testimony is unreliable due to the witness's vision issues and recent lens replacement, creating reasonable doubt.\",\n",
              "    'NOT GUILTY']],\n",
              "  'Rebecca Martin': [[\"Michelle makes a good point. Mrs. Cohen's testimony is definitely shaky now. The fact that she had just gotten new glasses and couldn't read the headline casts serious doubt on her ability to accurately identify the defendants.\",\n",
              "    'UNDECIDED'],\n",
              "   [\"The eyewitness testimony is unreliable due to the witness's vision issues and recent lens replacement, creating reasonable doubt.\",\n",
              "    'NOT GUILTY']]}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "metrics.py  –  Tiny helpers for jury‑simulation analysis\n",
        "========================================================\n",
        "Input format throughout:\n",
        "    runs: List[RunDict]\n",
        "    RunDict  = { \"Juror name\": [ [comment, stance], ... ] }\n",
        "\n",
        "All stances are normalised to upper‑case strings.\n",
        "\"\"\"\n",
        "\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "RunDict   = Dict[str, List[List[str]]]          # juror ➜ [[comment, stance], …]\n",
        "RunsList  = List[RunDict]\n",
        "\n",
        "\n",
        "# ─────────────────────────── Juror‑level ────────────────────────────\n",
        "def stance_flip_count(sequence: List[List[str]]) -> int:\n",
        "    \"\"\"Return how many times the juror changed stance during a run.\"\"\"\n",
        "    flips = 0\n",
        "    for (_, s1), (_, s2) in zip(sequence, sequence[1:]):\n",
        "        if s1 and s2 and s1 != s2:\n",
        "            flips += 1\n",
        "    return flips\n",
        "\n",
        "\n",
        "def first_commit_round(sequence: List[List[str]]) -> Optional[int]:\n",
        "    \"\"\"Index (0‑based) of first non‑UNDECIDED stance, or None if never commits.\"\"\"\n",
        "    for i, (_, stance) in enumerate(sequence):\n",
        "        if stance and stance != \"UNDECIDED\":\n",
        "            return i\n",
        "    return None\n",
        "\n",
        "\n",
        "def verbosity(sequence: List[List[str]]) -> float:\n",
        "    \"\"\"Average characters per comment for one juror in a run.\"\"\"\n",
        "    return sum(len(c) for c, _ in sequence) / len(sequence)\n",
        "\n",
        "\n",
        "# ─────────────────────────── Run‑level ──────────────────────────────\n",
        "def _round_stances(run: RunDict) -> List[List[str]]:\n",
        "    \"\"\"Helper: transposes run into [[s_juror1, s_juror2, …] per round].\"\"\"\n",
        "    rounds = max(len(seq) for seq in run.values())\n",
        "    jurors = list(run)\n",
        "    out = []\n",
        "    for r in range(rounds):\n",
        "        out.append([\n",
        "            (run[j][r][1] if r < len(run[j]) else \"UNDECIDED\").upper()\n",
        "            for j in jurors\n",
        "        ])\n",
        "    return out\n",
        "\n",
        "\n",
        "def consensus_speed(run: RunDict) -> Optional[int]:\n",
        "    \"\"\"\n",
        "    Round index where all jurors share the same *non‑UNDECIDED* stance.\n",
        "    Returns None if never reaches consensus before verdict block.\n",
        "    \"\"\"\n",
        "    for idx, stances in enumerate(_round_stances(run)):\n",
        "        uniq = {s for s in stances if s != \"UNDECIDED\"}\n",
        "        if len(uniq) == 1 and len(uniq) == len(set(stances)):\n",
        "            return idx\n",
        "    return None\n",
        "\n",
        "\n",
        "def majority_volatility(run: RunDict) -> int:\n",
        "    \"\"\"Count how many times the majority stance flips before verdict.\"\"\"\n",
        "    majority = []\n",
        "    for stances in _round_stances(run):\n",
        "        if all(s == \"UNDECIDED\" for s in stances):\n",
        "            majority.append(\"UNDECIDED\")\n",
        "        else:\n",
        "            mc = Counter([s for s in stances if s != \"UNDECIDED\"]).most_common(1)[0][0]\n",
        "            majority.append(mc)\n",
        "    return sum(m1 != m2 for m1, m2 in zip(majority, majority[1:]))\n",
        "\n",
        "\n",
        "def agreement_ratio_per_round(run: RunDict) -> List[float]:\n",
        "    \"\"\"List of % jurors sharing the majority stance at each round.\"\"\"\n",
        "    ratios = []\n",
        "    n = len(run)\n",
        "    for stances in _round_stances(run):\n",
        "        if all(s == \"UNDECIDED\" for s in stances):\n",
        "            ratios.append(0.0)\n",
        "        else:\n",
        "            cnt = Counter([s for s in stances if s != \"UNDECIDED\"])\n",
        "            ratios.append(max(cnt.values()) / n)\n",
        "    return ratios\n",
        "\n",
        "\n",
        "# ─────────────────────── Across‑runs aggregates ─────────────────────\n",
        "def verdict_distribution(runs: RunsList) -> Dict[str, int]:\n",
        "    \"\"\"How often each final stance (‘GUILTY’, ‘NOT GUILTY’, ‘UNDECIDED’) wins.\"\"\"\n",
        "    tally = Counter()\n",
        "    for run in runs:\n",
        "        finals = [seq[-1][1].upper() for seq in run.values() if seq]\n",
        "        if finals:                         # assume majority of finals decides case\n",
        "            winner = Counter(finals).most_common(1)[0][0]\n",
        "            tally[winner] += 1\n",
        "    return dict(tally)\n",
        "\n",
        "\n",
        "def avg_rounds_to_consensus(runs: RunsList) -> float:\n",
        "    \"\"\"Average consensus_speed across runs (ignores runs with None).\"\"\"\n",
        "    speeds = [s for r in runs if (s := consensus_speed(r)) is not None]\n",
        "    return sum(speeds) / len(speeds) if speeds else float(\"nan\")\n",
        "\n",
        "\n",
        "def juror_steadiness(runs: RunsList) -> Dict[str, float]:\n",
        "    \"\"\"Fraction of runs where each juror never flips stance.\"\"\"\n",
        "    counts = Counter()\n",
        "    steady = Counter()\n",
        "    for run in runs:\n",
        "        for juror, seq in run.items():\n",
        "            counts[juror] += 1\n",
        "            if stance_flip_count(seq) == 0:\n",
        "                steady[juror] += 1\n",
        "    return {j: steady[j] / counts[j] for j in counts}"
      ],
      "metadata": {
        "id": "qBMOPlIP1zCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, run in enumerate(runs_data, 1):\n",
        "    print(f\"\\n=== Run {idx} ===\")\n",
        "    for juror, seq in run.items():\n",
        "        print(f\"  {juror}\")\n",
        "        print(f\"    flips: {stance_flip_count(seq)}\")\n",
        "        print(f\"    first commit round: {first_commit_round(seq)}\")\n",
        "        print(f\"    verbosity (chars/comment): {verbosity(seq):.1f}\")\n",
        "    print(\"  run‑level:\")\n",
        "    print(f\"    consensus speed: {consensus_speed(run)}\")\n",
        "    print(f\"    majority volatility: {majority_volatility(run)}\")\n",
        "    print(f\"    agreement ratio per round: {agreement_ratio_per_round(run)}\")\n",
        "\n",
        "print(\"\\n=== Across runs ===\")\n",
        "print(\"  verdict distribution:\", verdict_distribution(runs_data))\n",
        "print(\"  avg rounds to consensus:\", avg_rounds_to_consensus(runs_data))\n",
        "print(\"  juror steadiness:\", juror_steadiness(runs_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4tzccXg6aNb",
        "outputId": "a2d78f86-491a-4090-f8db-ab0155e80696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run 1 ===\n",
            "  Michelle Chavez\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 158.5\n",
            "  Rebecca Martin\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 196.5\n",
            "  run‑level:\n",
            "    consensus speed: 1\n",
            "    majority volatility: 1\n",
            "    agreement ratio per round: [0.0, 1.0]\n",
            "\n",
            "=== Run 2 ===\n",
            "  Michelle Chavez\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 154.0\n",
            "  Rebecca Martin\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 189.0\n",
            "  run‑level:\n",
            "    consensus speed: 1\n",
            "    majority volatility: 1\n",
            "    agreement ratio per round: [0.0, 1.0]\n",
            "\n",
            "=== Run 3 ===\n",
            "  Michelle Chavez\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 160.5\n",
            "  Rebecca Martin\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 178.0\n",
            "  run‑level:\n",
            "    consensus speed: 1\n",
            "    majority volatility: 1\n",
            "    agreement ratio per round: [0.0, 1.0]\n",
            "\n",
            "=== Run 4 ===\n",
            "  Michelle Chavez\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 155.5\n",
            "  Rebecca Martin\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 204.0\n",
            "  run‑level:\n",
            "    consensus speed: 1\n",
            "    majority volatility: 1\n",
            "    agreement ratio per round: [0.0, 1.0]\n",
            "\n",
            "=== Run 5 ===\n",
            "  Michelle Chavez\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 159.5\n",
            "  Rebecca Martin\n",
            "    flips: 1\n",
            "    first commit round: 1\n",
            "    verbosity (chars/comment): 164.5\n",
            "  run‑level:\n",
            "    consensus speed: 1\n",
            "    majority volatility: 1\n",
            "    agreement ratio per round: [0.0, 1.0]\n",
            "\n",
            "=== Across runs ===\n",
            "  verdict distribution: {'NOT GUILTY': 5}\n",
            "  avg rounds to consensus: 1.0\n",
            "  juror steadiness: {'Michelle Chavez': 0.0, 'Rebecca Martin': 0.0}\n"
          ]
        }
      ]
    }
  ]
}